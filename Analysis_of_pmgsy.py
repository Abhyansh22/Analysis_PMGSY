# -*- coding: utf-8 -*-
"""Analysis of PMGSY Scheme.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nK1YvD34pi8jKkhXSSmk3d1-beLEabG0
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/PMGSY.csv')
area_df = pd.read_csv('/content/drive/MyDrive/state area.csv')
f2 = df.columns
f2

df.drop(['NO_OF_BRIDGES_SANCTIONED'], axis=1, inplace=True)
df.drop(['NO_OF_BRIDGES_COMPLETED'], axis=1, inplace=True)
df.drop(['NO_OF_BRIDGES_BALANCE'], axis=1, inplace=True)
display(df.columns)

# Calculate expenditure per km sanctioned

zero_values1 = (df['LENGTH_OF_ROAD_WORK_SANCTIONED_KM'] == 0).sum()
zero_values2 = (df['COST_OF_WORKS_SANCTIONED_LAKHS'] == 0).sum()
zero_values3 = (df['EXPENDITURE_OCCURED_LAKHS'] == 0).sum()
zero_values4 = (df['LENGTH_OF_ROAD_WORK_COMPLETED_KM'] == 0).sum()
print('Zero values encountered')
print(zero_values1, zero_values2, zero_values3, zero_values4)

df = df[df['LENGTH_OF_ROAD_WORK_SANCTIONED_KM'] != 0]
df = df[df['COST_OF_WORKS_SANCTIONED_LAKHS'] != 0]
df = df[df['EXPENDITURE_OCCURED_LAKHS'] != 0]
df = df[df['LENGTH_OF_ROAD_WORK_COMPLETED_KM'] != 0]

zero_values1 = (df['LENGTH_OF_ROAD_WORK_SANCTIONED_KM'] == 0).sum()
zero_values2 = (df['COST_OF_WORKS_SANCTIONED_LAKHS'] == 0).sum()
zero_values3 = (df['EXPENDITURE_OCCURED_LAKHS'] == 0).sum()
zero_values4 = (df['LENGTH_OF_ROAD_WORK_COMPLETED_KM'] == 0).sum()
print('Zero values after processing:')
print(zero_values1, zero_values2, zero_values3, zero_values4)


df['Sanctioned_expenditure_per_km'] = df['COST_OF_WORKS_SANCTIONED_LAKHS'] / df['LENGTH_OF_ROAD_WORK_SANCTIONED_KM']

# Calculate actual expenditure per km


df['actual_expenditure_per_km'] = df['EXPENDITURE_OCCURED_LAKHS'] / df['LENGTH_OF_ROAD_WORK_COMPLETED_KM']

df['Sanctioned_expenditure_per_km_in_rupees'] = df['Sanctioned_expenditure_per_km']*100000

df['actual_expenditure_per_km_in_rupees'] = df['actual_expenditure_per_km']*100000
# Example assuming we have an allocated expenditure column

df['difference'] = df['actual_expenditure_per_km_in_rupees'] - df['Sanctioned_expenditure_per_km_in_rupees']

# Display the updated DataFrame

display(df)

# Frequency distribution of 'State'
state_counts = df['STATE_NAME'].value_counts()
print(state_counts.agg('sum'))
print("State Frequency Distribution:\n", state_counts)

"""Inference: The scheme covers total of 2245 constructions going on all over country. the top 3 states with most constructions going on covered are Uttar Pradesh, Madhya Pradesh and Rajasthan."""

import pandas as pd
import matplotlib.pyplot as plt

# Group data by state and scheme, then sum the road lengths
scheme_summary = df.groupby(['STATE_NAME', 'PMGSY_SCHEME'])['LENGTH_OF_ROAD_WORK_COMPLETED_KM'].sum().unstack()

scheme_summary.to_csv('scheme_summary.csv')

# Plotting
scheme_summary.plot(kind='bar', stacked=True, figsize=(15, 6))
plt.title('Total Road Length by State and Scheme')
plt.xlabel('State')
plt.ylabel('Total Road Length (km)')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Scheme')
plt.tight_layout()
plt.show()

scheme_expenditure = df.groupby('PMGSY_SCHEME')['EXPENDITURE_OCCURED_LAKHS'].sum().sort_values(ascending=False).head(10)
total_expenditure = df.groupby('STATE_NAME')['EXPENDITURE_OCCURED_LAKHS'].sum().sort_values(ascending=False).head(10)

scheme_expenditure.to_csv('scheme_expenditure.csv')
total_expenditure.to_csv('total_expenditure.csv')
# Data for the outer pie chart
labels_outer = total_expenditure.keys()
sizes_outer = total_expenditure.values

fig, ax = plt.subplots(figsize=(10, 10))

# Outer pie chart
size = 0.3  # Adjust this to control the width of the outer ring
outer_colors = plt.cm.viridis(np.linspace(0, 1, len(total_expenditure)))  # Using viridis colormap
ax.pie(total_expenditure.values, radius=1, labels=total_expenditure.keys(), pctdistance = 0.85,
       autopct='%1.1f%%', startangle=90, colors=outer_colors,
       wedgeprops=dict(width=size, edgecolor='w'))

labels_inner = scheme_expenditure.keys()
sizes_inner = scheme_expenditure.values

# Inner pie chart
inner_colors = plt.cm.Set3(np.arange(len(scheme_expenditure)))  # Using Set3 colormap
ax.pie(scheme_expenditure.values, radius=1 - size,  # Adjust radius for nesting
       labels=scheme_expenditure.keys(), autopct='%1.1f%%', startangle=90,
       labeldistance=0.65, colors=inner_colors, pctdistance = 0.85,
       wedgeprops=dict(width=size, edgecolor='w'))

# Set title and aspect ratio
ax.set(aspect="equal", title='Expenditure Distribution')
plt.show()

df_balance = df.groupby('STATE_NAME')['LENGTH_OF_ROAD_WORK_BALANCE_KM'].sum().sort_values(ascending=False)

df_balance.to_csv('df_balance.csv')

plt.figure(figsize=(18, 6))
plt.title('Balance Road Length by State')
plt.xlabel('State')
plt.ylabel('Balance Road Length (km)')
plt.xticks(rotation=90, ha='right')
plt.bar(df_balance.index, df_balance.values)
plt

state_difference = df.groupby('STATE_NAME')['difference'].mean().sort_values(ascending=False)
display(state_difference)


state_difference.to_csv('state_difference.csv')
# Create the bar plot
plt.figure(figsize=(15, 6))
bars  = state_difference.plot(kind='bar')
plt.title('Average Expenditure Difference per km by State')
plt.xlabel('State')
plt.ylabel('Average Expenditure Difference (Rupees)')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0, ticks = [150000, 125000, 100000, 75000, 50000, 25000, 0, -15000])
plt.axhline(y=0, color='black', linestyle='-')
plt.tight_layout()
plt.show()

df_states = df['STATE_NAME'].unique()
area_df_states = area_df['STATE_NAME'].unique()
non_common_states_df = np.setdiff1d(df_states, area_df_states)
non_common_states_area_df = np.setdiff1d(area_df_states, df_states)
print(non_common_states_df)
print(non_common_states_area_df)

merged_df = pd.merge(df, area_df, on='STATE_NAME', how='left')
df['AREA_SQ_KM'] = merged_df['AREA_SQ_KM'].astype(float)
merged_df['Length Per SQ. KM'] = merged_df['LENGTH_OF_ROAD_WORK_COMPLETED_KM']/merged_df['AREA_SQ_KM']
merged_df.head(5).to_csv('merged_df.csv')

import matplotlib.pyplot as plt

# Group by state and calculate the mean of 'Length Per SQ. KM'
length_per_sqkm_by_state = merged_df.groupby('STATE_NAME')['Length Per SQ. KM'].mean().sort_values(ascending=True).tail(10)

length_per_sqkm_by_state.to_csv('length_per_sqkm_by_state.csv')

# Create the plot
plt.figure(figsize=(8, 10))  # Adjust figsize for better readability
plt.barh(length_per_sqkm_by_state.index, length_per_sqkm_by_state.values)  # Use barh for horizontal bars
plt.title('Average Road Length per sq km by State')
plt.ylabel('State')  # Swap xlabel and ylabel
plt.xlabel('Average Road Length per sq km')
plt.tight_layout()
plt.show()

"""Road Density: The last plot showing average road length per square kilometer provides insight into road density. States with higher values have a greater concentration of roads relative to their area, indicating better connectivity within the state. This is an important factor in accessibility and regional development."""

# Calculate total road length by state
state_road_length = merged_df.groupby('STATE_NAME')['LENGTH_OF_ROAD_WORK_COMPLETED_KM'].sum()

state_road_length.to_csv('state_road_length.csv')
# Sort states by total road length in descending order
top_10_states = state_road_length.sort_values(ascending=False).head(10)

# Calculate the total length for other states
other_states_length = state_road_length.sum() - top_10_states.sum()

# Create a pie chart
labels = list(top_10_states.index) + ['Other States']
sizes = list(top_10_states.values) + [other_states_length]

plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.title('Proportion of Total Road Length by State (Top 10 + Others)')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# 1. Calculate Total Road Length by State
state_road_length = merged_df.groupby('STATE_NAME')['LENGTH_OF_ROAD_WORK_COMPLETED_KM'].sum().reset_index()

# 2. Calculate Average Actual Cost per km by State
state_avg_cost = merged_df.groupby('STATE_NAME')['actual_expenditure_per_km'].mean().reset_index()

# 3. Merge with Area Data
state_summary_df = pd.merge(state_road_length, state_avg_cost, on='STATE_NAME')
state_summary_df = pd.merge(state_summary_df, area_df, on='STATE_NAME')

# 4. Select Desired Columns and Rename
state_summary_df = state_summary_df[['STATE_NAME', 'LENGTH_OF_ROAD_WORK_COMPLETED_KM', 'actual_expenditure_per_km', 'AREA_SQ_KM']]
state_summary_df = state_summary_df.rename(columns={
    'LENGTH_OF_ROAD_WORK_COMPLETED_KM': 'Total Road Length',
    'actual_expenditure_per_km': 'Average Actual Cost per km',
    'AREA_SQ_KM': 'State Area'
})

# Display the DataFrame
display(state_summary_df)

"""Hypothesis 1:

Null Hypothesis (H0): There is no significant relationship between the total road length completed and the state area.

Alternative Hypothesis (H1): There is a significant relationship between the total road length completed and the state area.

Interpretation:

If the p-value is less than our significance level (e.g., 0.05), we will reject the null hypothesis and conclude that there is a significant difference in the average actual expenditure per km between the different PMGSY schemes.
If the p-value is greater than our significance level, we will fail to reject the null hypothesis and conclude that there is no significant difference.
"""

import scipy.stats as stats

# Calculate Pearson correlation coefficient
correlation, p_value = stats.pearsonr(state_summary_df['Total Road Length'], state_summary_df['State Area'])

# Print the results
print(f"Pearson Correlation Coefficient: {correlation}")
print(f"P-value: {p_value}")

"""Based on the results"""